{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d3f3607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dea059",
   "metadata": {},
   "source": [
    "## Bernoulli\n",
    "\n",
    "The Bernoulli is a discrete Law that gets a parameter $p$ between $[0,1]$\n",
    "\n",
    "\n",
    "We will call from this moment the distribuition that have a Bernoulli distribution as the following\n",
    "\n",
    "\n",
    "$ X_i \\leadsto Bernoulli(p) $\n",
    "\n",
    "\n",
    "$X_i \\leadsto B(p)$\n",
    "\n",
    "\n",
    "\n",
    "With the following formula: $P_{p}(X=x)= p^{x}*(1-p)^{1-x}$\n",
    "\n",
    "\n",
    "where $x$ can assume the following values $ \\{0;1\\}$\n",
    "\n",
    "\n",
    "The idea behind this variable is that we're going to do an experiment, where we can get two answers, and only two answers that have a probability all besides that have probability zero, so after the experiment you'll see one result or the other.\n",
    "\n",
    "\n",
    "Let's deduce some fundamental conceps about this Law:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b71c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bernoulli(parameter,x):\n",
    "    if x==1:\n",
    "        probabilite = parameter\n",
    "    elif x==0:\n",
    "        probabilite = 1-parameter\n",
    "    else:\n",
    "        probabilite = 0\n",
    "    \n",
    "    return probabilite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1460a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bernoulli_accumulated_probability(parameter,k):\n",
    "    soma=0\n",
    "    if k>=0 :\n",
    "        soma = 1-parameter\n",
    "    if k>= 1:\n",
    "        soma = 1\n",
    "    return soma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7d4ad0",
   "metadata": {},
   "source": [
    "## Somme importants results\n",
    "\n",
    "By the definition:\n",
    "\n",
    "\n",
    "<div style=\"margin-bottom: 30px;\">\n",
    "    \n",
    "<br>\n",
    "    \n",
    "<center>\n",
    "$E[X_i] = \\sum_{k=1}^{\\infty} x*P(x=k)$\n",
    "</center\n",
    "<br> \n",
    "<br>\n",
    "<center>\n",
    "Mais $P(x=0) = (1-p) ; P(x=1) = p ; P(x=k)=0 \\forall x \\neq \\{1;0\\}$\n",
    "</center>\n",
    "<br>\n",
    "<center>\n",
    "$E[X_i] = p$\n",
    "</center>\n",
    "<br>\n",
    "   \n",
    "For $E[(X_i)^{2}]:$\n",
    "    \n",
    "<br>\n",
    "    \n",
    "<center>$E[(X_i)^{2}] = \\sum_{k=1}^{\\infty} x^{2}*P(x=k) \\iff E[(X_i)^{2}] = p$</center>\n",
    "    \n",
    "<br>\n",
    "    \n",
    "Then\n",
    "    \n",
    "<br>\n",
    "    \n",
    "<center>$ Var[X_i] = E[(X_i)^{2}] - (E[X_i])^{2} = p - p^{2} = p(1-p)$</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>$Var[X_i] = p(1-p)$</center>\n",
    "    \n",
    "<br>\n",
    "\n",
    "    \n",
    "    \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1846d5",
   "metadata": {},
   "source": [
    "### Some  Bernoulli estimators\n",
    "\n",
    "$\\mu_1(1) = \\overline{X_n}$\n",
    "\n",
    "The first estimators commes from the method of moments:\n",
    "\n",
    "<div style=\"margin-bottom 30px\">\n",
    "<br>\n",
    "    <center>$ E[\\overline{X_n}] =  E[\\frac{\\sum_{i=1}^{n} X_i}{n}] = \\frac{\\sum_{i=1}^{n} E[X_i]}{n} = \\frac{np}{n} = p$</center>\n",
    "<br>\n",
    "    <center>$\\tilde{p} = \\overline{X_n}$</center>\n",
    "<br>\n",
    "   The second estimator commes from the maximum likelihood estimation (MLE): \n",
    "<br>\n",
    "    \n",
    "Even with the variables are not independent we can right them as a produtory , we gonna optimize the fonction Ln because is easier to work \n",
    "    \n",
    "<br>\n",
    "    \n",
    "<center>$Ln(X,p)= \\prod_{i=1}^{n} p^{x_i}(1-p)^{x_i} = p^{\\sum_{i=1}^{n} x_i}(1-p)^{n-\\sum_{i=1}^{n} x_i}$</center>    \n",
    "<br>\n",
    "    \n",
    "<center>$\\frac{\\partial Ln(X,p)}{\\partial p} = (\\sum_{i=1}^{n} x_i)p^{(\\sum_{i=1}^{n} x_i)-1}(1-p)^{n-(\\sum_{i=1}^{n} x_i)}-p^{(\\sum_{i=1}^{n} x_i)}(n-(\\sum_{i=1}^{n} x_i))(1-p)^{n-(\\sum_{i=1}^{n} x_i)-1} =0 \\implies$  </center> \n",
    "    \n",
    "<br>\n",
    "    <center>$\\hat{p} = \\overline{X_n}$</center>\n",
    "<br>  \n",
    "Then the estimators are the same and the following analyses will be the same \n",
    "<br>\n",
    "    \n",
    "</div>\n",
    "\n",
    "\n",
    "#### Estimators List: \n",
    "\n",
    "\n",
    "\n",
    "1. $\\tilde{p} = \\overline{X_n}$(MM)\n",
    "\n",
    "2. $\\hat{p} = \\overline{X_n}$(MLE)\n",
    "\n",
    "\n",
    "#### Bias of an estimator\n",
    "\n",
    "<div style=\"margin-bottom= 30px;\">\n",
    "    <br>\n",
    "    <center>$b_{p}[\\hat{p}] = E[\\hat{p}] - p = 0$</center>\n",
    "    <br>\n",
    "    <center>Therefore he is not bias $b_{p}[\\hat{p}]=0$</center>\n",
    "    <br>\n",
    "</div>\n",
    "\n",
    "#### Risque of an estimator\n",
    "\n",
    "<div style=\"margin-bottom= 30px;\">\n",
    "    <br>\n",
    "    <center>$R_{p}[\\hat{p}] = (b_{p}[\\hat{p}])^{2} + Var[\\hat{p}]$</center>\n",
    "    <br>\n",
    "    <center>$Var[\\hat{p}]= Var[\\frac{\\sum_{k=1}^{n}X_i}{n}]= \\frac{\\sum_{k=1}^{n}Var[X_i]}{n^{2}}= \\frac{p(1-p)}{n}$</center>\n",
    "    <br>\n",
    "    <center>$R_{p}[\\hat{p}] =  \\frac{p(1-p)}{n}$</center>\n",
    "    <br>\n",
    "    <br>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "#### Consistency of an estimator\n",
    "\n",
    "Hypothèses et conditions\n",
    "\n",
    "1. $(X_n)$ a collection of iid samples from a random variable \n",
    "2. $E[X_i]<\\infty$\n",
    "\n",
    "<div style=\"margin-botto: 30px\">\n",
    "    <br>\n",
    "    <center>Using The strong law of large numbers(LLN) we get that :</center>\n",
    "    <br>\n",
    "    <center>${\\displaystyle {\\overline {X}}_{n}\\ {\\overset {\\text{a.s.}}{\\longrightarrow }}\\ E[X_i]=p \\qquad {\\textrm {when}}\\ n\\to \\infty .} $</center>\n",
    "    <br>\n",
    "    <center>And besides, we know that the function $f(x) = x$ is a continuous so using the continuity we have the following : </center>\n",
    "    <br>\n",
    "    <center>${\\displaystyle f({\\overline {X}}_{n}\\ ){\\overset {\\text{a.s.}}{\\longrightarrow }}\\ f(p) \\qquad {\\textrm {when}}\\ n\\to \\infty .} \\iff {\\displaystyle \\hat{p}{\\overset {\\text{a.s.}}{\\longrightarrow }}{p} \\qquad {\\textrm {when}}\\ n\\to \\infty .} \\implies {\\displaystyle \\hat{p}{\\overset {\\text{Prob}}{\\longrightarrow }}{p} \\qquad {\\textrm {when}}\\ n\\to \\infty .}$</center>\n",
    "    <br>\n",
    "    <center>Then $\\hat{p}$   is a consistent estimator. </center>\n",
    "    <br>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "#### Convergence speed\n",
    "\n",
    "Hypothèses et conditions\n",
    "\n",
    "1. $(X_n)$ a collection of iid samples from a random variable \n",
    "2. $E[X_i]=p$\n",
    "3. $Var[X_i]=p(1-p)<\\infty $\n",
    "\n",
    "\n",
    "<div style=\"margin-botto: 30px\">\n",
    "    <br>\n",
    "    <center>Using The central limit theorem (CLT) we get that :</center>\n",
    "    <br>\n",
    "    <center>${\\displaystyle \\frac{{\\sqrt {n}}\\left({\\bar {X}}_{n}-E[X_i] \\right)}{\\sqrt{Var[X_i]}}\\mathrel {\\overset {d}{\\longrightarrow }} {\\mathcal {N}}\\left(0,1\\right).}$</center>\n",
    "    <br>\n",
    "    <center>And we as know $\\hat{p} = \\overline{X_n}$ and $E[X_i] = p$ so , just substituing the values we have the following: : </center>\n",
    "    <br>\n",
    "    <center>${\\displaystyle \\frac{{\\sqrt {n}}\\left(\\hat{p}-p \\right)}{\\sqrt{p(1-p)}}\\mathrel {\\overset {d}{\\longrightarrow }} {\\mathcal {N}}\\left(0,1\\right).}$</center>\n",
    "    <br>\n",
    "    <center>Then the convergence speed is the following</center>\n",
    "    <br>\n",
    "    <center>${\\displaystyle {\\sqrt {n}}\\left(\\hat{p}- p \\right)\\mathrel {\\overset {d}{\\longrightarrow }} {\\mathcal {N}}\\left(0,p(1-p)\\right).}$</center>\n",
    "    <br>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
