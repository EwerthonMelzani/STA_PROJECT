{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee2e6179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e382a9",
   "metadata": {},
   "source": [
    "# DISCRETE LAWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53a87c0",
   "metadata": {},
   "source": [
    "## Geometric\n",
    "\n",
    "The Geometric is a discrete Law that gets a parameter $\\theta$ between $[0,1]$\n",
    "\n",
    "\n",
    "We will call from this moment the distribuition that have a Bernoulli distribution as the following\n",
    "\n",
    "\n",
    "$ X_i \\leadsto Geometric(\\theta) $\n",
    "\n",
    "\n",
    "$X_i \\leadsto G(\\theta)$\n",
    "\n",
    "\n",
    "With the following formula: $P_{\\theta}(X=k)= \\theta*(1-\\theta)^{k-1}$\n",
    "\n",
    "\n",
    "The meaning of k in this expression is the minimum of times that the event need to happens to reach the point where the result of the event is the one with probabilite $\\theta$.\n",
    "\n",
    "Let's deduce some fundamental conceps about this Law:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a87590d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Geometry(parameter,k):\n",
    "    probabilite=1-parameter\n",
    "    if k==0:\n",
    "        probabilite = 1\n",
    "    elif k>=1:\n",
    "        probabilite = probabilite**(k-1)\n",
    "        \n",
    "        \n",
    "    probabilite = probabilite*parameter\n",
    "    \n",
    "    return probabilite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28739507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Geometry_accumulated_probability(parameter,k):\n",
    "    soma=0\n",
    "    for i in range(1,k+1,1):\n",
    "        soma = soma + Geometry(parameter,i)\n",
    "    return soma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78e03f9",
   "metadata": {},
   "source": [
    "## Somme importants results\n",
    "\n",
    "Be $X_i \\leadsto Geometric(\\theta) \\$\n",
    "\n",
    "By the definition:\n",
    "\n",
    "\n",
    "<div style=\"margin-bottom: 30px;\">\n",
    "    \n",
    "<br>\n",
    "    \n",
    "<center>\n",
    "$E[X_i] = \\sum_{k=1}^{\\infty} x*P(x=k)$\n",
    "</center\n",
    "    \n",
    "<br>\n",
    "    \n",
    "$\\sum_{k=1}^{\\infty} xP(x=k)  \\iff \\sum_{i=1}^{\\infty} k\\theta(1-\\theta)^{k-1} \\iff \\theta\\sum_{i=1}^{\\infty} k(1-\\theta)^{k-1} \\tag{1}$\n",
    "\n",
    "<br>\n",
    "    \n",
    "<center> The fonction $f(x) = \\frac{1}{1-x} = \\sum_{k=0}^{\\infty} x^{k}$ is convergent for $x<1$ so all the operations that we gonna do after converge $\\implies$ </center>\n",
    "    \n",
    "<br>\n",
    "    \n",
    "$\\dot f(x) = \\sum_{k=0}^{\\infty} kx^{k-1} \\iff \\dot f(x) = \\sum_{k=1}^{\\infty} kx^{k-1} = (\\frac{1}{1-x})\\prime \\iff \\dot f(x) = \\frac{1}{(1-x)^{2}} \\tag{2}$\n",
    "    \n",
    "<br>\n",
    "    \n",
    "So we can apply this in the Eq(1) $\\implies$\n",
    "    \n",
    "<br>\n",
    "    \n",
    "<center> $E[X_i] = \\theta\\sum_{k=1}^{\\infty} k(1-\\theta)^{k-1} \\iff \\theta(\\frac{1}{(1-(1-\\theta))^{2}}) \\iff \\theta\\frac{1}{\\theta^{2}} $ </center>\n",
    "    \n",
    "<br>\n",
    "\n",
    "<center> $E[X_i] = \\frac{1}{\\theta} \\tag{X}$</center>\n",
    "    \n",
    "<br>\n",
    "   \n",
    "For $E[(X_i)^{2}]:$\n",
    "    \n",
    "<br>\n",
    "    \n",
    "<center>$E[(X_i)^{2}] = \\sum_{k=1}^{\\infty} x^{2}*P(x=k) \\iff E[(X_i)^{2}] = \\sum_{k=1}^{\\infty} x^{2}\\theta(1-\\theta)^{k-1} \\iff E[(X_i)^{2}] = \\theta\\sum_{k=1}^{\\infty} x^{2}(1-\\theta)^{k-1}$</center>\n",
    "    \n",
    "<br>\n",
    "     \n",
    "<center> The fonction $f(x) = \\frac{x}{1-x} = \\sum_{k=0}^{\\infty} x^{k+1}$ is convergent for $x<1$ so all the operations that we gonna do after converge $\\implies$ </center>\n",
    "    \n",
    "<br>\n",
    "\n",
    "<center> The fonction $f(x) = \\frac{x}{1-x} = \\sum_{k=0}^{\\infty} x^{k+1}$ is convergent for $x<1$ so all the operations that we gonna do after converge $\\implies$ </center>\n",
    "    \n",
    "<br>\n",
    "    \n",
    "<center> $ \\dot{\\dot{f}}(x) = (\\frac{x}{1-x})\\prime\\prime -\\sum_{k=1}^{\\infty} kx^{k-1} = \\sum_{k=1}^{\\infty} k^{2}x^{k-1} \\iff \\frac{2}{(1-x)^{3}} - \\frac{1}{(1-x)^{2}} = \\sum_{k=1}^{\\infty} k^{2}x^{k-1} \\iff \\sum_{k=1}^{\\infty} k^{2}x^{k-1} = \\frac{1+x}{(1-x)^{3}}$ </center>\n",
    "    \n",
    "<br>\n",
    "    \n",
    "<center>$E[(X_i)^{2}] = \\theta\\sum_{k=1}^{\\infty} k^{2}(1-\\theta)^{k-1} =  \\theta\\frac{1+(1-\\theta)}{(1-(1-\\theta))^{3}} = \\frac{2-\\theta)}{\\theta^{2}}$</center>\n",
    "    \n",
    "<br>\n",
    "    \n",
    "Then\n",
    "    \n",
    "<br>\n",
    "    \n",
    "<center>$ Var[X_i] = E[(X_i)^{2}] - (E[X_i])^{2} = \\frac{1-\\theta}{(\\theta)^{2}}$</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "    \n",
    "    \n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7974d3fa",
   "metadata": {},
   "source": [
    "### Some  Geometric estimators\n",
    "\n",
    "$\\mu_{1}(1) = \\overline{X_n}$\n",
    "\n",
    "The first estimators commes from the method of moments:\n",
    "\n",
    "<div style=\"margin-bottom: 30px;\">\n",
    "\n",
    "<br>\n",
    "<center>$E[X_n] = E[\\frac{\\sum_{k=1}^{n} X_i}{n}] = \\frac{\\sum_{k=1}^{n} E[X_i]}{n} = \\frac{nE[X_i]}{n} = \\frac{1}{\\theta}$</center>\n",
    "<br>\n",
    "\n",
    "<center>$\\tilde{\\theta} = \\frac{1}{\\overline{X_n}}$</center>\n",
    "    \n",
    "<br>\n",
    "    \n",
    "</div>\n",
    "\n",
    "\n",
    "The second estimator commes from the maximum likelihood estimation (MLE):\n",
    "\n",
    "<div style=\"margin-bottom: 30px;\">\n",
    "    \n",
    "    \n",
    "<br>\n",
    "    \n",
    "    \n",
    "Even with the variables are not independent we can right them as a produtory , we gonna optimize the fonction Ln because is easier to work \n",
    "    \n",
    "<br>\n",
    "    \n",
    "<center>$Ln(X,\\theta)= \\prod_{i=1}^{n} \\theta(1-\\theta)^{k_i-1} = (\\theta)^{n}(1-\\theta)^{-n}(1-\\theta)^{\\sum_{i=1}^{n} k_i}$</center>    \n",
    "<br>\n",
    "    \n",
    "<center>$\\frac{\\partial Ln(X,\\theta)}{\\partial \\theta} = n(\\theta)^{n-1}(1-\\theta)^{-n}(1-\\theta)^{\\sum_{i=1}^{n} k_i}- (\\theta)^{n}(\\sum_{i=1}^{n} k_i-n)(1-\\theta)^{(\\sum_{i=1}^{n} k_i) -n-1}=0 \\implies$  </center> \n",
    "    \n",
    "    \n",
    "<br>    \n",
    "<center> $\\hat{\\theta} = \\frac{1}{\\overline{X_n}}$ </center>\n",
    "<br>    \n",
    "   \n",
    "<br>\n",
    "Then the estimators are the same and the following analyses will be the same \n",
    "<br>\n",
    "    \n",
    "</div>\n",
    "\n",
    "\n",
    "#### Estimators List: \n",
    "\n",
    "\n",
    "\n",
    "1. $\\tilde{\\theta} = \\frac{1}{\\overline{X_n}}$(MM)\n",
    "\n",
    "2. $\\hat{\\theta} = \\frac{1}{\\overline{X_n}}$(MLE)\n",
    "\n",
    "\n",
    "#### Bias of an estimator\n",
    "\n",
    "<div style=\"margin-bottom= 30px;\">\n",
    "    <br>\n",
    "    <center>$b_{\\theta}[\\hat{\\theta}] = E[\\hat{\\theta}] - \\theta = 0$</center>\n",
    "    <br>\n",
    "    <center>Therefore he is not bias $b_{\\theta}[\\hat{\\theta}]=0$</center>\n",
    "    <br>\n",
    "</div>\n",
    "\n",
    "#### Risque of an estimator\n",
    "\n",
    "<div style=\"margin-bottom= 30px;\">\n",
    "    <br>\n",
    "    <center>$R_{\\theta}[\\hat{\\theta}] = (b_{\\theta}[\\hat{\\theta}])^{2} + Var[\\hat{\\theta}]$</center>\n",
    "    <br>\n",
    "    <center>$Var[\\hat{\\theta}]= Var[\\frac{n}{\\sum_{k=1}^{n}k_i}]= n^{2}\\frac{1}{\\sum_{k=1}^{n}Var[k_i]}= n\\frac{1}{Var[k_i]} = n\\frac{\\theta^{2}}{1-\\theta}$</center>\n",
    "    <br>\n",
    "    <center>$R_{\\theta}[\\hat{\\theta}] =  n\\frac{\\theta^{2}}{1-\\theta}$</center>\n",
    "    <br>\n",
    "</div>\n",
    "\n",
    "#### Consistency of an estimator\n",
    "\n",
    "Hypothèses et conditions\n",
    "\n",
    "1. $(X_n)$ a collection of iid samples from a random variable \n",
    "2. $E[X_i]<\\infty$\n",
    "\n",
    "<div style=\"margin-botto: 30px\">\n",
    "    <br>\n",
    "    <center>Using The strong law of large numbers(LLN) we get that :</center>\n",
    "    <br>\n",
    "    <center>${\\displaystyle {\\overline {X}}_{n}\\ {\\overset {\\text{a.s.}}{\\longrightarrow }}\\ \\mu \\qquad {\\textrm {when}}\\ n\\to \\infty .} $</center>\n",
    "    <br>\n",
    "    <center>And besides, we know that the function $f(x) = \\frac{1}{x}$ is a continuous except in $x=0$ so using the continuity we have the following : </center>\n",
    "    <br>\n",
    "    <center>${\\displaystyle f({\\overline {X}}_{n}\\ ){\\overset {\\text{a.s.}}{\\longrightarrow }}\\ f(\\mu) \\qquad {\\textrm {when}}\\ n\\to \\infty .} \\iff {\\displaystyle \\hat{\\theta}{\\overset {\\text{a.s.}}{\\longrightarrow }}{\\theta} \\qquad {\\textrm {when}}\\ n\\to \\infty .} \\implies {\\displaystyle \\hat{\\theta}{\\overset {\\text{Prob}}{\\longrightarrow }}{\\theta} \\qquad {\\textrm {when}}\\ n\\to \\infty .}$</center>\n",
    "    <br>\n",
    "    <center>Then $\\hat{\\theta}$   is a consistent estimator. </center>\n",
    "    <br>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "#### Convergence speed\n",
    "\n",
    "Hypothèses et conditions\n",
    "\n",
    "1. $(X_n)$ a collection of iid samples from a random variable \n",
    "2. $E[X_i]=\\mu$\n",
    "3. $Var[X_i]<\\infty $\n",
    "\n",
    "\n",
    "<div style=\"margin-botto: 30px\">\n",
    "    <br>\n",
    "    <center>Using The central limit theorem (CLT) we get that :</center>\n",
    "    <br>\n",
    "    <center>${\\displaystyle \\frac{{\\sqrt {n}}\\left({\\bar {X}}_{n}-\\mu \\right)}{\\sqrt{Var[X_i]}}\\mathrel {\\overset {d}{\\longrightarrow }} {\\mathcal {N}}\\left(0,1\\right).}$</center>\n",
    "    <br>\n",
    "    <center>And besides, we know that the function $f(x) = \\frac{1}{x}$ is continuous and $f\\prime(x) = \\frac{-1}{x^{2}}$is continuous two , then both are continuous except in $x=0$ so using the continuity and the delta method together,we have the following : </center>\n",
    "    <br>\n",
    "    <center>${\\displaystyle \\frac{{\\sqrt {n}}\\left(f({\\bar {X}}_{n})-f(\\mu) \\right)}{\\sqrt{Var[X_i]}}\\mathrel {\\overset {d}{\\longrightarrow }} {\\mathcal {N}}\\left(0,|(f\\prime(E[X_i]))^{2}|\\right).}$</center>\n",
    "    <br>\n",
    "    <center>${\\displaystyle {\\sqrt {n}}\\left(\\hat{\\theta}- \\theta \\right)\\mathrel {\\overset {d}{\\longrightarrow }} {\\mathcal {N}}\\left(0,\\frac{1-\\theta}{(\\theta)^{2}}|(f\\prime(\\frac{1}{\\theta}))^{2}|\\right).} \\iff {\\displaystyle {\\sqrt {n}}\\left(\\hat{\\theta}- \\theta \\right)\\mathrel {\\overset {d}{\\longrightarrow }} {\\mathcal {N}}\\left(0,(1-\\theta)(\\theta)^{2}\\right).}$</center>\n",
    "    <br>\n",
    "    <center>Then the convergence speed is the following</center>\n",
    "    <br>\n",
    "    <center>${\\displaystyle {\\sqrt {n}}\\left(\\hat{\\theta}- \\theta \\right)\\mathrel {\\overset {d}{\\longrightarrow }} {\\mathcal {N}}\\left(0,(1-\\theta)*\\theta^{2}\\right).}$</center>\n",
    "    <br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f7f1b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moment_Geometric(n,parameter):\n",
    "    soma = 0\n",
    "    for i in range(1,1000000,1):\n",
    "        soma = soma + (i**n)*Bernoulli(parameter,i)\n",
    "    \n",
    "    return soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd6ac76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
